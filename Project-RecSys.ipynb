{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d74f92-57dd-49d5-8e6d-b5ab8c7ee75c",
   "metadata": {},
   "source": [
    "# DSAIT4335 Recommender Systems\n",
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18281d7-d2fc-4a67-9bc9-21d25bad6cfc",
   "metadata": {},
   "source": [
    "In this project, you will work to build different recommendation models and evaluate the effectiveness of these models through offline experiments. The dataset used for the experiments is **MovieLens100K**, a movie recommendation dataset collected by GroupLens: https://grouplens.org/datasets/movielens/100k/. For more details, check the project description on Brightspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cbc07f-b579-4f9b-85b5-dc43c2d7ce48",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944993d6-8983-46cf-880f-753f65975811",
   "metadata": {},
   "source": [
    "The MovieLens100K is already splitted into 80% training and 20% test sets. Along with training and test sets, movies metadata as content information is also provided.\n",
    "\n",
    "**Expected file structure** for this assignment:   \n",
    "   \n",
    "   ```\n",
    "   RecSysProject/\n",
    "   ├── training.txt\n",
    "   ├── test.txt\n",
    "   ├── movies.txt\n",
    "   └── codes.ipynb\n",
    "   ```\n",
    "\n",
    "**Note:** Be sure to run all cells in each section sequentially, so that intermediate variables and packages are properly carried over to subsequent cells.\n",
    "\n",
    "**Note** Be sure to run all cells such that the submitted file contains the output of each cell.\n",
    "\n",
    "**Note** Feel free to add cells if you need more for answering a question.\n",
    "\n",
    "**Submission:** Answer all the questions in this jupyter-notebook file. Submit this jupyter-notebook file (your answers included) to Brightspace. Change the name of this jupyter-notebook file to your group number: example, group10 -> 10.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977945fa-a202-49c4-a41d-12ada7b437da",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302a2b5b-fdf1-41c8-b6a6-bc1cd453425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 2)) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 3)) (3.7.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: torch in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 5)) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 6)) (4.47.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
      "Requirement already satisfied: pip in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 10)) (24.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from torch->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from torch->-r requirements.txt (line 5)) (2023.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from torch->-r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from transformers->-r requirements.txt (line 6)) (0.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from transformers->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from transformers->-r requirements.txt (line 6)) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from transformers->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from transformers->-r requirements.txt (line 6)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from transformers->-r requirements.txt (line 6)) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers->-r requirements.txt (line 6)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maxde\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers->-r requirements.txt (line 6)) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch  # For BERT\n",
    "!pip install -r requirements.txt\n",
    "# you can refer https://huggingface.co/docs/transformers/en/model_doc/bert for various versions of the pre-trained model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3b0e3c-74d9-436b-b676-56bc2a8528a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the status of BERT installation:\n",
      "BERT libraries loaded successfully!\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# For BERT embeddings (install: pip install transformers torch)\n",
    "print(\"Check the status of BERT installation:\")\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    import torch\n",
    "    BERT_AVAILABLE = True\n",
    "    print(\"BERT libraries loaded successfully!\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "except ImportError:\n",
    "    BERT_AVAILABLE = False\n",
    "    print(\"BERT libraries not available. Install with: pip install transformers torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8055513b-9f14-4d18-b32a-7c2ee386e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine, correlation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "import re\n",
    "import time, math\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(10)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd1eff-8e8b-4f65-b92a-778107a256cc",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d220e9dc-3a45-4d25-b214-23d6555cb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        1       5\n",
       "1        1        2       3\n",
       "2        1        3       4\n",
       "3        1        4       3\n",
       "4        1        5       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data: (80000, 4)\n",
      "--------------------------------\n",
      "The test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        6       5\n",
       "1        1       10       3\n",
       "2        1       12       5\n",
       "3        1       14       5\n",
       "4        1       17       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the test data: (20000, 4)\n"
     ]
    }
   ],
   "source": [
    "# loading the training set and test set\n",
    "columns_name=['user_id','item_id','rating','timestamp']\n",
    "train_data = pd.read_csv('data/training.txt', sep='\\t', names=columns_name)\n",
    "test_data = pd.read_csv('data/test.txt', sep='\\t', names=columns_name)\n",
    "\n",
    "print(f'The training data:')\n",
    "display(train_data[['user_id','item_id','rating']].head())\n",
    "print(f'The shape of the training data: {train_data.shape}')\n",
    "print('--------------------------------')\n",
    "print(f'The test data:')\n",
    "display(test_data[['user_id','item_id','rating']].head())\n",
    "print(f'The shape of the test data: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e84160d-ef0e-4e58-8ace-307fb8cd5a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation, Children's, Comedy</td>\n",
       "      <td>A group of sentient toys, who pretend to be li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action, Adventure, Thriller</td>\n",
       "      <td>In 1986, MI6 agents James Bond and Alec Trevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>On New Year's Eve, bellhop Sam (Marc Lawrence)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>Action, Comedy, Drama</td>\n",
       "      <td>Chili Palmer is a Miami-based loan shark and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>After giving a guest lecture on criminal psych...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title                         genres  \\\n",
       "0        1   Toy Story (1995)  Animation, Children's, Comedy   \n",
       "1        2   GoldenEye (1995)    Action, Adventure, Thriller   \n",
       "2        3  Four Rooms (1995)                       Thriller   \n",
       "3        4  Get Shorty (1995)          Action, Comedy, Drama   \n",
       "4        5     Copycat (1995)         Crime, Drama, Thriller   \n",
       "\n",
       "                                         description  \n",
       "0  A group of sentient toys, who pretend to be li...  \n",
       "1  In 1986, MI6 agents James Bond and Alec Trevel...  \n",
       "2  On New Year's Eve, bellhop Sam (Marc Lawrence)...  \n",
       "3  Chili Palmer is a Miami-based loan shark and m...  \n",
       "4  After giving a guest lecture on criminal psych...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('data/movies.txt',names=['item_id','title','genres','description'],sep='\\t')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d50b57f-b07a-49b0-ad8c-31566a355cc7",
   "metadata": {},
   "source": [
    "# Task 1) Implementation of different recommendation models as well as a hybrid model combining those recommendation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55e25ab-353d-4a7c-bf68-9deb201bfbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training hybrid recommender on 943 users and 1650 items...\n",
      "Training individual models...\n",
      "  Loaded predictions for Matrix Factorization from checkpoint.\n",
      "Finished training individual models.\n",
      "Started linear regression...\n",
      "[INFO] Visualization saved to: plots\\linear_regression_rating_2025-10-25_17-13-44.png\n",
      "Finished rating linear regression, weights are:\n",
      "  Matrix Factorization: 1.0064251219379128\n",
      "Precomputing predictions...\n",
      "Finished computing predictions, model is ready to use.\n"
     ]
    }
   ],
   "source": [
    "from ast import List\n",
    "from recommendation_algorithms.hybrid_recommender import HybridRecommender\n",
    "from recommendation_algorithms.matrix_factorization import MatrixFactorizationSGD\n",
    "from recommendation_algorithms.bayesian_probabilistic_ranking import BayesianProbabilisticRanking\n",
    "from recommendation_algorithms.item_knn import ItemKNN\n",
    "from recommendation_algorithms.user_knn import UserKNN\n",
    "\n",
    "# TODO add others\n",
    "item_knn = ItemKNN(k=8)\n",
    "user_knn = UserKNN(k=8)\n",
    "matrix_factorization = MatrixFactorizationSGD()\n",
    "bpr = BayesianProbabilisticRanking()\n",
    "rating_recommenders = [matrix_factorization, item_knn, user_knn]\n",
    "ranking_recommenders = [matrix_factorization, bpr, item_knn, user_knn]\n",
    "max_k = 10 # Recommendation list size\n",
    "ranking_weights = {\n",
    "\t'Matrix Factorization': 0.25,\n",
    "\t'Bayesian Probabilistic Ranking': 0.25,\n",
    "\t'Item KNN': 0.25,\n",
    "\t'User KNN': 0.25,\n",
    "}\n",
    "hybrid_recommender = HybridRecommender(train_data, rating_recommenders, ranking_recommenders, max_k, ranking_weights, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8890e56-5f6e-4958-aa5a-b540cd176a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted & actual ranking for user 12\n",
      "  1: predicted: (169.0, 2.04675061048853) & actual: (4, 5)\n",
      "  2: predicted: (64.0, 1.5009403017981806) & actual: (69, 5)\n",
      "  3: predicted: (174.0, 1.4737886923553705) & actual: (88, 5)\n",
      "  4: predicted: (313.0, 1.4581417319824816) & actual: (98, 5)\n",
      "  5: predicted: (173.0, 1.4577209608831918) & actual: (161, 5)\n",
      "  6: predicted: (12.0, 1.4542368113017816) & actual: (174, 5)\n",
      "  7: predicted: (272.0, 1.4535505704551945) & actual: (216, 5)\n",
      "  8: predicted: (50.0, 1.4319056428968764) & actual: (238, 5)\n",
      "  9: predicted: (408.0, 1.4278526031084255) & actual: (242, 5)\n",
      "  10: predicted: (22.0, 1.4267876525919148) & actual: (591, 5)\n"
     ]
    }
   ],
   "source": [
    "user_id = 12\n",
    "item_id = 2\n",
    "# predicted_score = hybrid_recommender.predict_score(user_id, item_id)\n",
    "# actual_score = train_data.loc[((train_data['user_id'] == user_id) & (train_data['item_id'] == item_id)), 'rating'].values[0]\n",
    "# print(f'Predicted score {predicted_score} for user {user_id} and item {item_id}, actual score: {actual_score}.')\n",
    "\n",
    "predicted_ranking = hybrid_recommender.predict_ranking(user_id, max_k)\n",
    "user_df = train_data.loc[(train_data['user_id'] == user_id), ['item_id', 'rating']]\n",
    "actual_ranking = (\n",
    "        user_df.nlargest(max_k, 'rating')\n",
    "        .apply(lambda row: (row['item_id'], row['rating']), axis=1)\n",
    "        .tolist()\n",
    ")\n",
    "print(f\"Predicted & actual ranking for user {user_id}\")\n",
    "for i in range(len(predicted_ranking)):\n",
    "    print(f\"  {i + 1}: predicted: {predicted_ranking[i]} & actual: {actual_ranking[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6b136",
   "metadata": {},
   "source": [
    "#### Test BPR Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdec53a-dec3-4239-bd0f-9a6899462878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommendation_algorithms.bayesian_probabilistic_ranking import BayesianProbabilisticRanking\n",
    "\n",
    "bpr = BayesianProbabilisticRanking()\n",
    "bpr.train(train_data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00d56470f8c17c",
   "metadata": {},
   "source": [
    "#### User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30067f3d7d12045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T11:44:12.159522Z",
     "start_time": "2025-10-17T11:44:12.152453Z"
    }
   },
   "outputs": [],
   "source": [
    "from recommendation_algorithms.user_knn import UserKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb140805004ce3ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T11:42:24.355645Z",
     "start_time": "2025-10-17T11:42:24.343402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 697.74it/s]\n"
     ]
    }
   ],
   "source": [
    "u_knn = UserKNN(2)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 4],\n",
    "    'item_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2],\n",
    "    'rating':  [5, 4, 3, 3, 4, 3, 2, 4, 5, 5, 3]\n",
    "})\n",
    "\n",
    "u_knn.train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8487e3b01eef3a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T11:42:26.246004Z",
     "start_time": "2025-10-17T11:42:26.240833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_that_rated_i: \n",
      "[1, 2, 3]\n",
      "sim_matrix_masked: \n",
      "          1    2         3    4\n",
      "1  0.000000  0.0 -0.755929  1.0\n",
      "2  0.000000  0.0  0.000000  0.0\n",
      "3 -0.755929  0.0  0.000000  0.0\n",
      "sims: \n",
      "2    0.000000\n",
      "1   -0.755929\n",
      "Name: 3, dtype: float64\n",
      "ni \n",
      "[2 1]\n",
      "rvi \n",
      "[4 2]\n",
      "rv \n",
      "[4.         3.33333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.333333333333334)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_knn.predict_score(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec71ee48956d3a",
   "metadata": {},
   "source": [
    "### Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f66bec8cba09ee64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T11:11:26.993371Z",
     "start_time": "2025-10-17T11:11:26.986874Z"
    }
   },
   "outputs": [],
   "source": [
    "from recommendation_algorithms.item_knn import ItemKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "434d1fa07ba81470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T11:11:29.485574Z",
     "start_time": "2025-10-17T11:11:29.478316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 1528.35it/s]\n"
     ]
    }
   ],
   "source": [
    "i_knn = ItemKNN(2)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 4],\n",
    "    'item_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2],\n",
    "    'rating':  [5, 4, 3, 3, 4, 3, 2, 4, 5, 5, 3]\n",
    "})\n",
    "\n",
    "i_knn.train(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61fb737186f18fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T11:11:30.026384Z",
     "start_time": "2025-10-17T11:11:30.022047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.954941986653667)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_knn.predict_score(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f712c-2895-4962-ad06-85da032fd597",
   "metadata": {},
   "source": [
    "# Task 2) Experiments for both rating prediction and ranking tasks, and conducting offline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56177635-1c91-4ca6-845e-5ae874726b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f3a3e5-adef-4144-b7ad-f5f55696972d",
   "metadata": {},
   "source": [
    "# Task 3) Implement baselines for both rating prediction and ranking tasks, and perform experiments with those baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5710b4-8bae-42f0-8990-41e7cec7433f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e10661af-16f3-41f1-b09a-0307f70c344f",
   "metadata": {},
   "source": [
    "# Task 4) Analysis of recommendation models. Analyzing the coefficients of hybrid model and the success of recommendation models for different users' groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23377855-cc19-4b06-a497-712a892ae3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9914f603-b893-471c-9622-4437855dd8fa",
   "metadata": {},
   "source": [
    "# Task 5) Evaluation of beyond accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a0e4b-adbe-4673-82f8-a75761666fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
